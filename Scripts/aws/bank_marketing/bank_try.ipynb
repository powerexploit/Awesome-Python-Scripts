{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import boto3\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset : downloading - preprocessing - uploading"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First download the [dataset](http://archive.ics.uci.edu/ml/machine-learning-databases/00222/bank-additional.zip) and keep it in the data folder with name 'bankadditionalfull.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data = pd.read_csv('data/bankadditionalfull.csv', sep=';', index_col=0)\n",
    "raw_data.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finds categorical data from the dataframe\n",
    "# Needed for creating the Data Schema, we'll see afterwards\n",
    "\n",
    "def identify_categorical(dataframe):   \n",
    "    total = dataframe.columns\n",
    "    numerical = dataframe._get_numeric_data().columns\n",
    "    dictionary = {'CATEGORICAL': list(set(total) - set(numerical)), 'NUMERIC':list(numerical)}\n",
    "    return dictionary\n",
    "\n",
    "features = identify_categorical(raw_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before starting off with using amazon services, do [this](https://boto3.amazonaws.com/v1/documentation/api/latest/guide/quickstart.html)\n",
    "\n",
    "And it is mandatory to save the data in either S3 or RedShift, otherwise you cannot use Amazon ML"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## If data already exists in S3 Bucket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking if a bucket exists already \n",
    "s3 = boto3.client('s3')\n",
    "response = s3.list_buckets()\n",
    "\n",
    "bucket = [buckets['Name'] for buckets in response['Buckets']]\n",
    "\n",
    "# If you already have uploaded the data file to S3 Bucket, you would get the list of buckets in bucket variable\n",
    "print(bucket)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## If data is in your local machine and not yet uploaded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For users who do not have a S3 Bucket created\n",
    "s3 = boto3.client('s3')\n",
    "s3.create_bucket(Bucket='thinkdifferentnow') # Specify any name, all the buckets should have a unique name.\n",
    "s3.upload_file('data/bankadditionalfull.csv', 'thinkdifferentnow', 'bankadditionalfull.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- To know more about using boto3 to access S3 buckets click [here](https://boto3.amazonaws.com/v1/documentation/api/latest/guide/s3-example-creating-buckets.html)\n",
    "\n",
    "- Since we have saved our dataset in the S3 Bucket, we can now move forward to creating ML model.\n",
    "\n",
    "- First we need to create a datasource. A datasource is basically the information of our dataset. Like, \n",
    "    * Where is it stored\n",
    "    * Info of the data features (aka categorical/numerical/text/binary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![DataSource](images/createdatasource.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = boto3.client('machinelearning')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creating JSON file for DataSchema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copied this from boto3 documentation\n",
    "# Even you copy it as it is\n",
    "DataSchema = { \n",
    "    \"version\": \"1.0\",\n",
    "    \"targetFieldName\": \"y\",\n",
    "    \"dataFormat\": \"CSV\",\n",
    "    \"dataFileContainsHeader\": 'true', # Set it to true because, CSV contains feature names.\n",
    "    }\n",
    "\n",
    "# Now we will fill the \"attributes\"\n",
    "attributes = []\n",
    "for featureType in list(features.keys()):\n",
    "    for featureName in features[featureType]:\n",
    "        attributes.append({'fieldName':featureName, 'fieldType':featureType})\n",
    "        \n",
    "DataSchema['attributes'] = attributes  \n",
    "\n",
    "# Saving DataSchema in a JSON file\n",
    "with open('data/dataschema.json', 'w') as outfile:\n",
    "    json.dump(DataSchema, outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make sure for Amazon ML you set your region name to 'us-east-1' or 'eu-west-1'\n",
    "# As AML works only for US East(Virginia) and EU (Ireland) as of now.\n",
    "\n",
    "\n",
    "# Make sure you wait for 4-5 minutes once you execute this code cell.\n",
    "_ = client.create_data_source_from_s3(\n",
    "    DataSourceId='ds-sYkrd9KZMme', # Any ID will do\n",
    "    DataSourceName='tryingboto',  # Any name will do\n",
    "    DataSpec={\n",
    "        'DataLocationS3': 's3://bankclassification/bankadditionalfull_.csv', # s3://bucket_name/file_name\n",
    "        # DataScehma is the string of the DataSchema dictionary that we created before. You can copy-paste it from dataschema.json that we created.\n",
    "        'DataSchema': '{\"version\": \"1.0\", \"targetFieldName\": \"y\", \"dataFormat\": \"CSV\", \"dataFileContainsHeader\": \"true\", \"attributes\": [{\"fieldName\": \"day_of_week\", \"fieldType\": \"CATEGORICAL\"}, {\"fieldName\": \"y\", \"fieldType\": \"BINARY\"}, {\"fieldName\": \"contact\", \"fieldType\": \"CATEGORICAL\"}, {\"fieldName\": \"education\", \"fieldType\": \"CATEGORICAL\"}, {\"fieldName\": \"loan\", \"fieldType\": \"CATEGORICAL\"}, {\"fieldName\": \"poutcome\", \"fieldType\": \"CATEGORICAL\"}, {\"fieldName\": \"default\", \"fieldType\": \"CATEGORICAL\"}, {\"fieldName\": \"marital\", \"fieldType\": \"CATEGORICAL\"}, {\"fieldName\": \"job\", \"fieldType\": \"CATEGORICAL\"}, {\"fieldName\": \"month\", \"fieldType\": \"CATEGORICAL\"}, {\"fieldName\": \"housing\", \"fieldType\": \"CATEGORICAL\"}, {\"fieldName\": \"duration\", \"fieldType\": \"NUMERIC\"}, {\"fieldName\": \"campaign\", \"fieldType\": \"NUMERIC\"}, {\"fieldName\": \"pdays\", \"fieldType\": \"NUMERIC\"}, {\"fieldName\": \"previous\", \"fieldType\": \"NUMERIC\"}, {\"fieldName\": \"emp.var.rate\", \"fieldType\": \"NUMERIC\"}, {\"fieldName\": \"cons.price.idx\", \"fieldType\": \"NUMERIC\"}, {\"fieldName\": \"cons.conf.idx\", \"fieldType\": \"NUMERIC\"}, {\"fieldName\": \"euribor3m\", \"fieldType\": \"NUMERIC\"}, {\"fieldName\": \"nr.employed\", \"fieldType\": \"NUMERIC\"}]}'\n",
    "    },\n",
    "    ComputeStatistics=True\n",
    ")\n",
    "\n",
    "# It turns out, surprisingly it took 16 mins of compute time for creating the datasource :("
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once Data Source is created, you'd get this:\n",
    "\n",
    "![Data Source](images/dataSource.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "__ = client.create_ml_model(\n",
    "    MLModelId='mlmodelid_',\n",
    "    MLModelName='marketingbank',\n",
    "    MLModelType='BINARY',   # Amazon ML has 3 types of model types: BINARY | MULTICLASS | REGRESSION\n",
    "    TrainingDataSourceId='ds-sYkrd9KZMme'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once the model is trained, you would get this in your Dashboard\n",
    "\n",
    "![ML model trained](images/mlmodel.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To create batch predictions on the test data\n",
    "# We again need to create a datasource for the dataset\n",
    "# And enter the datasource id below\n",
    "\n",
    "___ = client.create_batch_prediction(\n",
    "    BatchPredictionId='batchpredictionid_',\n",
    "    BatchPredictionName='predictresults',\n",
    "    MLModelId='mlmodelid_',\n",
    "    BatchPredictionDataSourceId='ds-CmsaR7xPeTU',\n",
    "    OutputUri='s3://bankclassification/'\n",
    ")\n",
    "\n",
    "# OutputUri specifies in which S3 bucket directory shall the prediction folder be placed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After executing above code cell, if you go and check your Dashboard you would see something like this:\n",
    "\n",
    "![Batch Predictions](images/batchPredictions.png)\n",
    "\n",
    "\n",
    "\n",
    "![Completed](images/batchPredictionsCompleted.png)\n",
    "\n",
    "\n",
    "And you can find your predictions folder with a name of batch-prediction in the give S3 bucket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
